{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from skimage import color, exposure, transform\n",
    "\n",
    "NUM_CLASSES = 89 # 88 notes plus one class for silence\n",
    "NUM_MFCC = 30\n",
    "NUM_CEPS = 13\n",
    "\n",
    "X_train = pickle.load(open('data/tdnn/mfcc_feat_train.pkl', 'rb'))\n",
    "Y_train = pickle.load(open('data/tdnn/target_train.pkl', 'rb'))\n",
    "\n",
    "num_samples = X_train.shape[0]\n",
    "random_indexes = np.random.permutation(num_samples)\n",
    "\n",
    "X_train = X_train[random_indexes, :]\n",
    "Y_train = Y_train[random_indexes]\n",
    "\n",
    "X_test = pickle.load(open('data/tdnn/mfcc_feat_test.pkl', 'rb'))\n",
    "Y_test = pickle.load(open('data/tdnn/target_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1047703, 13, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1047703, 89)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(64, (2), padding='same',\n",
    "                     input_shape=(NUM_CEPS, NUM_MFCC),\n",
    "                     activation='relu'))\n",
    "    model.add(Conv1D(64, (2), activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv1D(64, (3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv1D(64, (3), activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv1D(128, (4), padding='same',\n",
    "                     activation='relu'))\n",
    "#     model.add(Conv1D(128, (2), activation='relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=(2)))\n",
    "#     model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "model = cnn_model()\n",
    "\n",
    "# let's train the model using SGD + momentum\n",
    "lr = 0.001\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 838162 samples, validate on 209541 samples\n",
      "Epoch 1/10\n",
      "838162/838162 [==============================] - 143s 170us/step - loss: 0.5276 - acc: 0.8607 - val_loss: 0.2502 - val_acc: 0.9426\n",
      "Epoch 2/10\n",
      "838162/838162 [==============================] - 143s 170us/step - loss: 0.2987 - acc: 0.9268 - val_loss: 0.2164 - val_acc: 0.9482\n",
      "Epoch 3/10\n",
      "838162/838162 [==============================] - 142s 169us/step - loss: 0.2599 - acc: 0.9377 - val_loss: 0.1912 - val_acc: 0.9567\n",
      "Epoch 4/10\n",
      "838162/838162 [==============================] - 165s 197us/step - loss: 0.2395 - acc: 0.9435 - val_loss: 0.1818 - val_acc: 0.9575\n",
      "Epoch 5/10\n",
      "838162/838162 [==============================] - 148s 176us/step - loss: 0.2265 - acc: 0.9472 - val_loss: 0.1775 - val_acc: 0.9617\n",
      "Epoch 6/10\n",
      "838162/838162 [==============================] - 139s 165us/step - loss: 0.2157 - acc: 0.9503 - val_loss: 0.1714 - val_acc: 0.9633\n",
      "Epoch 7/10\n",
      "838162/838162 [==============================] - 142s 169us/step - loss: 0.2086 - acc: 0.9521 - val_loss: 0.1592 - val_acc: 0.9645\n",
      "Epoch 8/10\n",
      "838162/838162 [==============================] - 141s 168us/step - loss: 0.2028 - acc: 0.9536 - val_loss: 0.1580 - val_acc: 0.9653\n",
      "Epoch 9/10\n",
      "838162/838162 [==============================] - 144s 171us/step - loss: 0.1975 - acc: 0.9551 - val_loss: 0.1696 - val_acc: 0.9657\n",
      "Epoch 10/10\n",
      "838162/838162 [==============================] - 145s 172us/step - loss: 0.1939 - acc: 0.9561 - val_loss: 0.1580 - val_acc: 0.9666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x128b1eed0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return lr * (0.1 ** int(epoch / 10))\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[LearningRateScheduler(lr_schedule),\n",
    "                     ModelCheckpoint('models/model.h5', save_best_only=True)]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "#model.save(\"models/tdnn_fulldata.h5\")\n",
    "\n",
    "model = load_model('models/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model.predict(X_train)\n",
    "Y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Notes predicted by simple max of probabilities\n",
    "test_pred_notes = np.argmax(Y_test_pred, axis=1)\n",
    "\n",
    "train_act_notes = np.argmax(Y_train, axis=1)\n",
    "test_act_notes = np.argmax(Y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 88 88 88 88\n",
      " 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88\n",
      " 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88\n",
      " 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88\n",
      " 88 88 88 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 88 88 88 88 88 88 88 88 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35]\n",
      "[39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 88 88\n",
      " 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88\n",
      " 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88\n",
      " 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88\n",
      " 88 88 88 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 88 88 88 88 88 88 88 88 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35]\n"
     ]
    }
   ],
   "source": [
    "print(test_pred_notes[2500:2700])\n",
    "print(test_act_notes[2500:2700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from write_midi_mono import write_midi_mono "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_midi_mono(test_pred_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(Y_train_pred, open(\"data/hmm/train_probs.pkl\", 'wb'))\n",
    "pickle.dump(Y_test_pred, open(\"data/hmm/test_probs.pkl\", 'wb'))\n",
    "\n",
    "pickle.dump(train_act_notes, open(\"data/hmm/train_notes.pkl\", 'wb'))\n",
    "pickle.dump(test_act_notes, open(\"data/hmm/test_notes.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
